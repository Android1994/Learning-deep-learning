{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225029\n"
     ]
    }
   ],
   "source": [
    "#####数据分析\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "\n",
    "print(train_data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1225029\n"
     ]
    }
   ],
   "source": [
    "# for i in train_data['landmark_id']:\n",
    "#     if i == 14950:\n",
    "#         print(i)\n",
    "#         break\n",
    "# ##0-14950\n",
    "\n",
    "\n",
    "#train_data['landmark_id'][1225028]\n",
    "\n",
    "count=0\n",
    "for i in train_data['id']:\n",
    "    count+=1    \n",
    "print(count) ###1225029：0-1225028\n",
    "\n",
    "# n=0\n",
    "# for img_range_low in range(0,1181279,43751):\n",
    "#     img_range_high=img_range_low+43751+1\n",
    "#     for img_num in range(img_range_low,img_range_high,1):\n",
    "#         a=train_data['id'][img_num]\n",
    "#         n=img_range_low\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c90ca2e5e4e8e94c.jpg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "train_data = pd.read_csv('labels_split/train-0.csv')\n",
    "_id=train_data['id'][0]\n",
    "print(_id+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############内存不够\n",
    "import os\n",
    "from PIL import Image\n",
    "file_dir=\"data/train_img/\"\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "count=0\n",
    "for img_name in train_data['id']:\n",
    "    \n",
    "    img_path=file_dir+img_name+\".jpg\"\n",
    "    if os.path.exists(img_path):\n",
    "        im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "        imResize = im.resize((299, 299))\n",
    "        imageData = np.array(imResize)\n",
    "        images.append(imageData)\n",
    "        #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "        labels.append(train_data['landmark_id'][count])\n",
    "    \n",
    "    count+=1\n",
    "        \n",
    "# images_array = np.array(images)\n",
    "# labels_array = np.array(labels)\n",
    "X = np.array(images)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:1253: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2598, 299, 299, 3)\n",
      "Train on 2338 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 163s 70ms/step - loss: 8.8489 - acc: 0.0449 - val_loss: 8.7548 - val_acc: 0.0346\n",
      "(2603, 299, 299, 3)\n",
      "Train on 2342 samples, validate on 261 samples\n",
      "Epoch 1/1\n",
      "2342/2342 [==============================] - 149s 63ms/step - loss: 8.7726 - acc: 0.0384 - val_loss: 8.8968 - val_acc: 0.0383\n",
      "(2603, 299, 299, 3)\n",
      "Train on 2342 samples, validate on 261 samples\n",
      "Epoch 1/1\n",
      "1712/2342 [====================>.........] - ETA: 38s - loss: 8.8143 - acc: 0.0356"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5bad3f5dc696>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14951\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################切分数据--1225029：   以及尝试训练\n",
    "#####数据分析\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split #数据拆分\n",
    "from keras.utils import np_utils #编码器\n",
    "from keras.models import load_model\n",
    "\n",
    "import keras.backend.tensorflow_backend as KTF  \n",
    "KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0}))) \n",
    "\n",
    "from inception_v4 import create_inception_v4\n",
    "\n",
    "#model = create_inception_v4()\n",
    "model = load_model('temp.h5')\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "file_dir=\"data/train_img/\"\n",
    "\n",
    "step=2612 ##18284,9142，4571\n",
    "BATCH_SIZE=16 ##16\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "count=0\n",
    "\n",
    "#model = create_inception_v4()\n",
    "\n",
    "for epoch_t in range(0,50):\n",
    "    for img_range_low in range(0,1225029-step,step):\n",
    "        img_range_high=img_range_low+step+1\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for img_num in range(img_range_low,img_range_high,1):\n",
    "            img_path=file_dir+train_data['id'][img_num]+\".jpg\"\n",
    "            if os.path.exists(img_path):\n",
    "                im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "                imResize = im.resize((299, 299))\n",
    "                imageData = np.array(imResize)\n",
    "                images.append(imageData)\n",
    "                #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "                labels.append(train_data['landmark_id'][img_num])\n",
    "\n",
    "        X = np.array(images)\n",
    "        y = np.array(labels)\n",
    "        print(X.shape)\n",
    "        \n",
    "        if(X.shape[0]>32):\n",
    "            X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=30)\n",
    "\n",
    "            y_train = np_utils.to_categorical(y_train,14951) #矢量编码\n",
    "            y_test = np_utils.to_categorical(y_test,14951)\n",
    "\n",
    "            model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=1,batch_size=BATCH_SIZE,verbose=1)\n",
    "    \n",
    "        \n",
    "# images_array = np.array(images)\n",
    "# labels_array = np.array(labels)\n",
    "# X = np.array(images)\n",
    "# y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################按label划分train.csv\n",
    "import csv\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "\n",
    "count=0\n",
    "for i in train_data['id']:\n",
    "    count+=1    \n",
    "print(count) ###1225029：0-1225028\n",
    "\n",
    "for i in range(0,count):\n",
    "    _id=train_data['id'][i]\n",
    "    _landId=train_data['landmark_id'][i]\n",
    "    \n",
    "    file_num = int(_landId/20)\n",
    "    file_path=\"labels_split/train-%d.csv\"%(file_num)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        da = [_id, _landId]\n",
    "        # 写入数据\n",
    "        csvFile = open(file_path, \"a+\")\n",
    "        writer = csv.writer(csvFile)\n",
    "        # 写入的内容都是以列表的形式传入函数\n",
    "        writer.writerow(da)\n",
    "        csvFile.close()\n",
    "    else:\n",
    "        fileHeader = [\"id\", \"landmark_id\"]\n",
    "        # 假设我们要写入的是以下两行数据\n",
    "        da = [_id, _landId]\n",
    "        # 写入数据\n",
    "        csvFile = open(file_path, \"a+\")\n",
    "        writer = csv.writer(csvFile)\n",
    "        # 写入的内容都是以列表的形式传入函数\n",
    "        writer.writerow(fileHeader)\n",
    "        writer.writerow(da)\n",
    "        csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/topology.py:1253: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv_num:35\n",
      "(656, 299, 299, 3)\n",
      "Train on 590 samples, validate on 66 samples\n",
      "Epoch 1/10\n",
      "590/590 [==============================] - 54s 92ms/step - loss: 15.5886 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "590/590 [==============================] - 37s 63ms/step - loss: 13.3882 - acc: 0.0000e+00 - val_loss: 13.4595 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "590/590 [==============================] - 37s 63ms/step - loss: 11.5033 - acc: 0.0000e+00 - val_loss: 11.0913 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "590/590 [==============================] - 38s 65ms/step - loss: 10.5815 - acc: 0.0000e+00 - val_loss: 10.0759 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "590/590 [==============================] - 38s 65ms/step - loss: 9.8755 - acc: 0.0000e+00 - val_loss: 9.0815 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "590/590 [==============================] - 38s 65ms/step - loss: 9.0221 - acc: 0.0000e+00 - val_loss: 8.4870 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "590/590 [==============================] - 38s 65ms/step - loss: 8.0034 - acc: 0.0017 - val_loss: 7.0678 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "590/590 [==============================] - 38s 65ms/step - loss: 7.1198 - acc: 0.0102 - val_loss: 6.4644 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "590/590 [==============================] - 38s 64ms/step - loss: 6.4025 - acc: 0.0458 - val_loss: 6.3687 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "590/590 [==============================] - 38s 64ms/step - loss: 5.6848 - acc: 0.0831 - val_loss: 5.8324 - val_acc: 0.2424\n",
      "csv_num:36\n",
      "(880, 299, 299, 3)\n",
      "Train on 792 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "792/792 [==============================] - 52s 65ms/step - loss: 11.0328 - acc: 0.0000e+00 - val_loss: 10.6145 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 8.3835 - acc: 0.0088 - val_loss: 9.2506 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 5.5827 - acc: 0.2361 - val_loss: 6.4319 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 4.1898 - acc: 0.4545 - val_loss: 4.6753 - val_acc: 0.5795\n",
      "Epoch 5/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 3.5343 - acc: 0.5189 - val_loss: 3.7561 - val_acc: 0.5795\n",
      "Epoch 6/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 3.2894 - acc: 0.5442 - val_loss: 3.0916 - val_acc: 0.5795\n",
      "Epoch 7/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 3.1695 - acc: 0.5568 - val_loss: 2.9049 - val_acc: 0.5795\n",
      "Epoch 8/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 3.0037 - acc: 0.5682 - val_loss: 2.7736 - val_acc: 0.5795\n",
      "Epoch 9/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 3.0852 - acc: 0.5619 - val_loss: 1.9080 - val_acc: 0.5909\n",
      "Epoch 10/10\n",
      "792/792 [==============================] - 51s 64ms/step - loss: 2.9239 - acc: 0.5669 - val_loss: 1.8676 - val_acc: 0.5909\n",
      "csv_num:37\n",
      "(1762, 299, 299, 3)\n",
      "Train on 1585 samples, validate on 177 samples\n",
      "Epoch 1/10\n",
      "1585/1585 [==============================] - 102s 65ms/step - loss: 10.5507 - acc: 0.0000e+00 - val_loss: 9.3712 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 6.4629 - acc: 0.0442 - val_loss: 4.7755 - val_acc: 0.1695\n",
      "Epoch 3/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 4.4944 - acc: 0.1287 - val_loss: 6.8244 - val_acc: 0.1356\n",
      "Epoch 4/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.9862 - acc: 0.1451 - val_loss: 3.0415 - val_acc: 0.1808\n",
      "Epoch 5/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.8393 - acc: 0.1401 - val_loss: 2.5841 - val_acc: 0.1864\n",
      "Epoch 6/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.7388 - acc: 0.1558 - val_loss: 2.7861 - val_acc: 0.1864\n",
      "Epoch 7/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.6624 - acc: 0.1552 - val_loss: 3.0175 - val_acc: 0.1864\n",
      "Epoch 8/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.5590 - acc: 0.1659 - val_loss: 3.1553 - val_acc: 0.1864\n",
      "Epoch 9/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.5657 - acc: 0.1552 - val_loss: 3.3238 - val_acc: 0.1808\n",
      "Epoch 10/10\n",
      "1585/1585 [==============================] - 102s 64ms/step - loss: 3.5436 - acc: 0.1628 - val_loss: 3.8359 - val_acc: 0.1808\n",
      "csv_num:38\n",
      "(1581, 299, 299, 3)\n",
      "Train on 1422 samples, validate on 159 samples\n",
      "Epoch 1/10\n",
      "1422/1422 [==============================] - 92s 64ms/step - loss: 11.8297 - acc: 7.0323e-04 - val_loss: 9.5536 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 5.1820 - acc: 0.2792 - val_loss: 3.6895 - val_acc: 0.4843\n",
      "Epoch 3/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 3.6992 - acc: 0.4318 - val_loss: 3.9993 - val_acc: 0.4214\n",
      "Epoch 4/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 3.4041 - acc: 0.4655 - val_loss: 3.2652 - val_acc: 0.4591\n",
      "Epoch 5/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 3.1508 - acc: 0.4796 - val_loss: 2.5193 - val_acc: 0.4906\n",
      "Epoch 6/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 3.0348 - acc: 0.4859 - val_loss: 2.3225 - val_acc: 0.4969\n",
      "Epoch 7/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 2.9864 - acc: 0.4880 - val_loss: 2.3736 - val_acc: 0.4969\n",
      "Epoch 8/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 3.0236 - acc: 0.4909 - val_loss: 3.3420 - val_acc: 0.4591\n",
      "Epoch 9/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 2.8468 - acc: 0.4944 - val_loss: 4.4737 - val_acc: 0.4151\n",
      "Epoch 10/10\n",
      "1422/1422 [==============================] - 91s 64ms/step - loss: 2.8877 - acc: 0.4902 - val_loss: 2.7278 - val_acc: 0.4906\n",
      "csv_num:39\n",
      "(1782, 299, 299, 3)\n",
      "Train on 1603 samples, validate on 179 samples\n",
      "Epoch 1/10\n",
      "1603/1603 [==============================] - 104s 65ms/step - loss: 9.7957 - acc: 0.0156 - val_loss: 4.7219 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 4.0402 - acc: 0.3044 - val_loss: 2.0827 - val_acc: 0.4637\n",
      "Epoch 3/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 3.2877 - acc: 0.3649 - val_loss: 1.8716 - val_acc: 0.4637\n",
      "Epoch 4/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 3.0877 - acc: 0.3868 - val_loss: 1.7391 - val_acc: 0.4637\n",
      "Epoch 5/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.9475 - acc: 0.3843 - val_loss: 1.7070 - val_acc: 0.4637\n",
      "Epoch 6/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.9087 - acc: 0.3949 - val_loss: 2.4706 - val_acc: 0.4358\n",
      "Epoch 7/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.9119 - acc: 0.4005 - val_loss: 2.0944 - val_acc: 0.4637\n",
      "Epoch 8/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.8253 - acc: 0.3943 - val_loss: 2.1760 - val_acc: 0.4525\n",
      "Epoch 9/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.8069 - acc: 0.4067 - val_loss: 1.7875 - val_acc: 0.4637\n",
      "Epoch 10/10\n",
      "1603/1603 [==============================] - 103s 64ms/step - loss: 2.7230 - acc: 0.3980 - val_loss: 1.7104 - val_acc: 0.4525\n",
      "csv_num:40\n",
      "(875, 299, 299, 3)\n",
      "Train on 787 samples, validate on 88 samples\n",
      "Epoch 1/10\n",
      "787/787 [==============================] - 51s 64ms/step - loss: 12.5776 - acc: 0.0000e+00 - val_loss: 9.4614 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 9.0258 - acc: 0.0025 - val_loss: 7.2766 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 7.1687 - acc: 0.0534 - val_loss: 5.3225 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 5.7084 - acc: 0.1067 - val_loss: 7.3449 - val_acc: 0.0341\n",
      "Epoch 5/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 4.8997 - acc: 0.1677 - val_loss: 7.0607 - val_acc: 0.2273\n",
      "Epoch 6/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 4.3332 - acc: 0.2058 - val_loss: 6.4624 - val_acc: 0.2614\n",
      "Epoch 7/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 4.0479 - acc: 0.2363 - val_loss: 2.8041 - val_acc: 0.4205\n",
      "Epoch 8/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 3.9947 - acc: 0.2452 - val_loss: 3.0988 - val_acc: 0.4205\n",
      "Epoch 9/10\n",
      "787/787 [==============================] - 51s 65ms/step - loss: 3.8345 - acc: 0.2490 - val_loss: 2.9794 - val_acc: 0.4091\n",
      "Epoch 10/10\n",
      "787/787 [==============================] - 51s 64ms/step - loss: 3.7456 - acc: 0.2579 - val_loss: 3.0523 - val_acc: 0.4091\n",
      "csv_num:41\n",
      "(1644, 299, 299, 3)\n",
      "Train on 1479 samples, validate on 165 samples\n",
      "Epoch 1/10\n",
      "1479/1479 [==============================] - 96s 65ms/step - loss: 11.4445 - acc: 6.7613e-04 - val_loss: 8.2856 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 7.1239 - acc: 0.0845 - val_loss: 4.2369 - val_acc: 0.4424\n",
      "Epoch 3/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 4.6757 - acc: 0.2914 - val_loss: 3.6584 - val_acc: 0.4000\n",
      "Epoch 4/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.8840 - acc: 0.3489 - val_loss: 4.1814 - val_acc: 0.3697\n",
      "Epoch 5/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.5680 - acc: 0.3631 - val_loss: 3.5139 - val_acc: 0.4061\n",
      "Epoch 6/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.4699 - acc: 0.3725 - val_loss: 2.5272 - val_acc: 0.4485\n",
      "Epoch 7/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.3869 - acc: 0.3847 - val_loss: 2.6758 - val_acc: 0.4424\n",
      "Epoch 8/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.2876 - acc: 0.3989 - val_loss: 2.8923 - val_acc: 0.4424\n",
      "Epoch 9/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.2738 - acc: 0.3996 - val_loss: 3.6789 - val_acc: 0.4121\n",
      "Epoch 10/10\n",
      "1479/1479 [==============================] - 95s 64ms/step - loss: 3.2392 - acc: 0.3915 - val_loss: 3.4178 - val_acc: 0.4242\n",
      "csv_num:42\n",
      "(731, 299, 299, 3)\n",
      "Train on 657 samples, validate on 74 samples\n",
      "Epoch 1/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 14.8101 - acc: 0.0000e+00 - val_loss: 16.0340 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 10.7435 - acc: 0.0000e+00 - val_loss: 10.3921 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 9.8092 - acc: 0.0000e+00 - val_loss: 9.0808 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "657/657 [==============================] - 42s 64ms/step - loss: 8.8960 - acc: 0.0000e+00 - val_loss: 7.8106 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 7.5661 - acc: 0.0167 - val_loss: 6.4511 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 6.0053 - acc: 0.1553 - val_loss: 5.1461 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 5.1152 - acc: 0.2374 - val_loss: 3.8795 - val_acc: 0.4324\n",
      "Epoch 8/10\n",
      "657/657 [==============================] - 42s 65ms/step - loss: 4.5812 - acc: 0.2694 - val_loss: 3.0842 - val_acc: 0.4324\n",
      "Epoch 9/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 4.3295 - acc: 0.2801 - val_loss: 2.6436 - val_acc: 0.4324\n",
      "Epoch 10/10\n",
      "657/657 [==============================] - 43s 65ms/step - loss: 4.1217 - acc: 0.2922 - val_loss: 2.8213 - val_acc: 0.4189\n",
      "csv_num:43\n",
      "(2388, 299, 299, 3)\n",
      "Train on 2149 samples, validate on 239 samples\n",
      "Epoch 1/10\n",
      "2149/2149 [==============================] - 139s 65ms/step - loss: 10.4591 - acc: 0.0000e+00 - val_loss: 7.7256 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2149/2149 [==============================] - 139s 65ms/step - loss: 7.6829 - acc: 0.0042 - val_loss: 5.3975 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "2149/2149 [==============================] - 139s 64ms/step - loss: 5.7665 - acc: 0.1657 - val_loss: 3.2318 - val_acc: 0.4226\n",
      "Epoch 4/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 4.7005 - acc: 0.2462 - val_loss: 2.7183 - val_acc: 0.4226\n",
      "Epoch 5/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 4.2421 - acc: 0.2913 - val_loss: 3.0513 - val_acc: 0.4100\n",
      "Epoch 6/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 3.9535 - acc: 0.3099 - val_loss: 2.9730 - val_acc: 0.4142\n",
      "Epoch 7/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 3.8160 - acc: 0.3169 - val_loss: 2.4429 - val_acc: 0.4268\n",
      "Epoch 8/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 3.7206 - acc: 0.3239 - val_loss: 2.7856 - val_acc: 0.4100\n",
      "Epoch 9/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 3.5554 - acc: 0.3346 - val_loss: 3.0445 - val_acc: 0.4059\n",
      "Epoch 10/10\n",
      "2149/2149 [==============================] - 138s 64ms/step - loss: 3.4936 - acc: 0.3327 - val_loss: 2.6920 - val_acc: 0.4100\n",
      "(716, 299, 299, 3)\n",
      "Train on 644 samples, validate on 72 samples\n",
      "Epoch 1/10\n",
      "644/644 [==============================] - 42s 66ms/step - loss: 3.5226 - acc: 0.3276 - val_loss: 2.3742 - val_acc: 0.3472\n",
      "Epoch 2/10\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 3.5628 - acc: 0.3276 - val_loss: 2.5724 - val_acc: 0.3472\n",
      "Epoch 3/10\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 3.6116 - acc: 0.3307 - val_loss: 2.5740 - val_acc: 0.3472\n",
      "Epoch 4/10\n",
      "644/644 [==============================] - 42s 64ms/step - loss: 3.5918 - acc: 0.3245 - val_loss: 2.7508 - val_acc: 0.3472\n",
      "Epoch 5/10\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 3.5377 - acc: 0.3307 - val_loss: 2.7721 - val_acc: 0.3333\n",
      "Epoch 6/10\n",
      "644/644 [==============================] - 42s 64ms/step - loss: 3.5813 - acc: 0.3199 - val_loss: 3.1740 - val_acc: 0.3194\n",
      "Epoch 7/10\n",
      "644/644 [==============================] - 42s 65ms/step - loss: 3.5461 - acc: 0.3261 - val_loss: 3.1856 - val_acc: 0.3056\n",
      "Epoch 8/10\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 3.4266 - acc: 0.3416 - val_loss: 2.1524 - val_acc: 0.3472\n",
      "Epoch 9/10\n",
      "644/644 [==============================] - 42s 65ms/step - loss: 3.4648 - acc: 0.3307 - val_loss: 2.1436 - val_acc: 0.3472\n",
      "Epoch 10/10\n",
      "644/644 [==============================] - 41s 64ms/step - loss: 3.4168 - acc: 0.3385 - val_loss: 2.1434 - val_acc: 0.3472\n",
      "csv_num:44\n",
      "(944, 299, 299, 3)\n",
      "Train on 849 samples, validate on 95 samples\n",
      "Epoch 1/10\n",
      "849/849 [==============================] - 54s 64ms/step - loss: 14.7680 - acc: 0.0000e+00 - val_loss: 13.9603 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 10.9557 - acc: 0.0000e+00 - val_loss: 9.5837 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 8.0654 - acc: 0.0271 - val_loss: 7.2105 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 5.5062 - acc: 0.1555 - val_loss: 4.9534 - val_acc: 0.3368\n",
      "Epoch 5/10\n",
      "849/849 [==============================] - 55s 65ms/step - loss: 4.5695 - acc: 0.2544 - val_loss: 3.0965 - val_acc: 0.3158\n",
      "Epoch 6/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 4.0787 - acc: 0.2627 - val_loss: 2.8270 - val_acc: 0.4000\n",
      "Epoch 7/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 3.7313 - acc: 0.2827 - val_loss: 2.5077 - val_acc: 0.4105\n",
      "Epoch 8/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 3.6625 - acc: 0.3039 - val_loss: 2.4328 - val_acc: 0.3895\n",
      "Epoch 9/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 3.4857 - acc: 0.3251 - val_loss: 2.8090 - val_acc: 0.3789\n",
      "Epoch 10/10\n",
      "849/849 [==============================] - 55s 64ms/step - loss: 3.4115 - acc: 0.3545 - val_loss: 2.6345 - val_acc: 0.2737\n",
      "csv_num:45\n",
      "(622, 299, 299, 3)\n",
      "Train on 559 samples, validate on 63 samples\n",
      "Epoch 1/10\n",
      "559/559 [==============================] - 37s 66ms/step - loss: 13.2751 - acc: 0.0000e+00 - val_loss: 14.4663 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 10.2405 - acc: 0.0000e+00 - val_loss: 10.2708 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "559/559 [==============================] - 36s 64ms/step - loss: 8.7308 - acc: 0.0000e+00 - val_loss: 8.4614 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 7.4611 - acc: 0.0215 - val_loss: 6.9223 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 6.2415 - acc: 0.0429 - val_loss: 5.5870 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 5.4253 - acc: 0.0805 - val_loss: 4.3879 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 4.8552 - acc: 0.1216 - val_loss: 3.5099 - val_acc: 0.1905\n",
      "Epoch 8/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 4.6325 - acc: 0.1181 - val_loss: 3.2892 - val_acc: 0.1746\n",
      "Epoch 9/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 4.3661 - acc: 0.1163 - val_loss: 3.1380 - val_acc: 0.1746\n",
      "Epoch 10/10\n",
      "559/559 [==============================] - 36s 64ms/step - loss: 4.3040 - acc: 0.1216 - val_loss: 3.1028 - val_acc: 0.1270\n",
      "csv_num:46\n",
      "(522, 299, 299, 3)\n",
      "Train on 469 samples, validate on 53 samples\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 13.6268 - acc: 0.0000e+00 - val_loss: 14.6821 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 10.8761 - acc: 0.0000e+00 - val_loss: 11.0587 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 10.2122 - acc: 0.0000e+00 - val_loss: 9.7223 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 9.7167 - acc: 0.0000e+00 - val_loss: 9.0120 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 9.0006 - acc: 0.0000e+00 - val_loss: 8.1856 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 8.1665 - acc: 0.0021 - val_loss: 7.3245 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 7.3559 - acc: 0.0256 - val_loss: 6.4217 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 6.5259 - acc: 0.0661 - val_loss: 4.9031 - val_acc: 0.2830\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 6.0658 - acc: 0.0938 - val_loss: 4.1605 - val_acc: 0.2830\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 5.4496 - acc: 0.1045 - val_loss: 3.6137 - val_acc: 0.2830\n",
      "csv_num:47\n",
      "(224, 299, 299, 3)\n",
      "Train on 201 samples, validate on 23 samples\n",
      "Epoch 1/10\n",
      "201/201 [==============================] - 14s 70ms/step - loss: 13.4337 - acc: 0.0000e+00 - val_loss: 11.9763 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 12.1853 - acc: 0.0000e+00 - val_loss: 11.0807 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 11.1684 - acc: 0.0000e+00 - val_loss: 10.3562 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 10.6107 - acc: 0.0000e+00 - val_loss: 9.7942 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 10.1496 - acc: 0.0000e+00 - val_loss: 9.3173 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 9.7903 - acc: 0.0000e+00 - val_loss: 9.1110 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 9.3041 - acc: 0.0000e+00 - val_loss: 8.6754 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 9.0727 - acc: 0.0000e+00 - val_loss: 8.2645 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 8.6346 - acc: 0.0000e+00 - val_loss: 7.5779 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "201/201 [==============================] - 13s 65ms/step - loss: 8.2063 - acc: 0.0149 - val_loss: 7.1449 - val_acc: 0.0000e+00\n",
      "csv_num:48\n",
      "(1881, 299, 299, 3)\n",
      "Train on 1692 samples, validate on 189 samples\n",
      "Epoch 1/10\n",
      "1692/1692 [==============================] - 110s 65ms/step - loss: 10.2566 - acc: 0.0000e+00 - val_loss: 7.6590 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 7.1757 - acc: 0.1194 - val_loss: 6.2480 - val_acc: 0.5556\n",
      "Epoch 3/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 3.6544 - acc: 0.5000 - val_loss: 2.3959 - val_acc: 0.6561\n",
      "Epoch 4/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 3.0249 - acc: 0.5585 - val_loss: 2.2329 - val_acc: 0.6508\n",
      "Epoch 5/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.8666 - acc: 0.5632 - val_loss: 1.6885 - val_acc: 0.6931\n",
      "Epoch 6/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.7250 - acc: 0.5715 - val_loss: 2.0216 - val_acc: 0.6667\n",
      "Epoch 7/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.7086 - acc: 0.5697 - val_loss: 1.8353 - val_acc: 0.6772\n",
      "Epoch 8/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.6876 - acc: 0.5733 - val_loss: 7.4799 - val_acc: 0.3915\n",
      "Epoch 9/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.6511 - acc: 0.5739 - val_loss: 3.9922 - val_acc: 0.5767\n",
      "Epoch 10/10\n",
      "1692/1692 [==============================] - 109s 64ms/step - loss: 2.6118 - acc: 0.5863 - val_loss: 1.8026 - val_acc: 0.6878\n",
      "csv_num:49\n",
      "(1143, 299, 299, 3)\n",
      "Train on 1028 samples, validate on 115 samples\n",
      "Epoch 1/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 12.0157 - acc: 0.0000e+00 - val_loss: 9.5436 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 8.7358 - acc: 0.0000e+00 - val_loss: 6.6267 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 6.3509 - acc: 0.0545 - val_loss: 4.0688 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 5.0089 - acc: 0.1547 - val_loss: 3.2307 - val_acc: 0.2087\n",
      "Epoch 5/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 4.2185 - acc: 0.2072 - val_loss: 2.9088 - val_acc: 0.2087\n",
      "Epoch 6/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 3.9955 - acc: 0.2383 - val_loss: 3.1308 - val_acc: 0.3217\n",
      "Epoch 7/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 3.7868 - acc: 0.2422 - val_loss: 3.0948 - val_acc: 0.2348\n",
      "Epoch 8/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 3.8056 - acc: 0.2500 - val_loss: 2.9525 - val_acc: 0.2261\n",
      "Epoch 9/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 3.5606 - acc: 0.2481 - val_loss: 2.5665 - val_acc: 0.3565\n",
      "Epoch 10/10\n",
      "1028/1028 [==============================] - 66s 64ms/step - loss: 3.5330 - acc: 0.2422 - val_loss: 2.5412 - val_acc: 0.3565\n",
      "csv_num:50\n",
      "(1074, 299, 299, 3)\n",
      "Train on 966 samples, validate on 108 samples\n",
      "Epoch 1/10\n",
      "966/966 [==============================] - 63s 65ms/step - loss: 13.6165 - acc: 0.0000e+00 - val_loss: 12.2360 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 9.9564 - acc: 0.0000e+00 - val_loss: 9.1536 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 8.4538 - acc: 0.0052 - val_loss: 6.9657 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 6.9014 - acc: 0.1263 - val_loss: 4.6714 - val_acc: 0.4352\n",
      "Epoch 5/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 5.7171 - acc: 0.2371 - val_loss: 3.5081 - val_acc: 0.4630\n",
      "Epoch 6/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 5.0564 - acc: 0.2857 - val_loss: 4.0070 - val_acc: 0.4074\n",
      "Epoch 7/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 4.5813 - acc: 0.3054 - val_loss: 2.3603 - val_acc: 0.4630\n",
      "Epoch 8/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 4.2113 - acc: 0.3416 - val_loss: 2.6905 - val_acc: 0.4444\n",
      "Epoch 9/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 4.0435 - acc: 0.3364 - val_loss: 2.5144 - val_acc: 0.4537\n",
      "Epoch 10/10\n",
      "966/966 [==============================] - 62s 64ms/step - loss: 3.9099 - acc: 0.3613 - val_loss: 3.8260 - val_acc: 0.3889\n",
      "csv_num:51\n",
      "(1157, 299, 299, 3)\n",
      "Train on 1041 samples, validate on 116 samples\n",
      "Epoch 1/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 12.1995 - acc: 0.0000e+00 - val_loss: 9.8089 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 9.4700 - acc: 0.0000e+00 - val_loss: 7.8852 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 7.8116 - acc: 0.0653 - val_loss: 6.3712 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 6.2274 - acc: 0.1940 - val_loss: 4.4762 - val_acc: 0.5086\n",
      "Epoch 5/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 5.0744 - acc: 0.3103 - val_loss: 3.6929 - val_acc: 0.4914\n",
      "Epoch 6/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 4.4021 - acc: 0.4006 - val_loss: 2.4428 - val_acc: 0.5517\n",
      "Epoch 7/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 4.1398 - acc: 0.4457 - val_loss: 2.4860 - val_acc: 0.5517\n",
      "Epoch 8/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 3.8855 - acc: 0.4601 - val_loss: 2.3782 - val_acc: 0.5517\n",
      "Epoch 9/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 3.5820 - acc: 0.4890 - val_loss: 2.6610 - val_acc: 0.5345\n",
      "Epoch 10/10\n",
      "1041/1041 [==============================] - 67s 64ms/step - loss: 3.4290 - acc: 0.5014 - val_loss: 2.4534 - val_acc: 0.5431\n",
      "csv_num:52\n",
      "(1683, 299, 299, 3)\n",
      "Train on 1514 samples, validate on 169 samples\n",
      "Epoch 1/10\n",
      "1514/1514 [==============================] - 98s 64ms/step - loss: 11.4268 - acc: 0.0033 - val_loss: 8.7534 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 6.9260 - acc: 0.1262 - val_loss: 4.7889 - val_acc: 0.3669\n",
      "Epoch 3/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 5.0732 - acc: 0.2180 - val_loss: 3.3062 - val_acc: 0.3728\n",
      "Epoch 4/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 4.3360 - acc: 0.2853 - val_loss: 3.4114 - val_acc: 0.3787\n",
      "Epoch 5/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.9926 - acc: 0.3151 - val_loss: 3.2312 - val_acc: 0.3728\n",
      "Epoch 6/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.7029 - acc: 0.3382 - val_loss: 3.0628 - val_acc: 0.3550\n",
      "Epoch 7/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.6809 - acc: 0.3276 - val_loss: 3.3710 - val_acc: 0.3550\n",
      "Epoch 8/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.5247 - acc: 0.3573 - val_loss: 5.7380 - val_acc: 0.3373\n",
      "Epoch 9/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.4899 - acc: 0.3540 - val_loss: 2.5940 - val_acc: 0.3787\n",
      "Epoch 10/10\n",
      "1514/1514 [==============================] - 97s 64ms/step - loss: 3.4527 - acc: 0.3567 - val_loss: 2.6460 - val_acc: 0.3787\n",
      "csv_num:53\n",
      "(727, 299, 299, 3)\n",
      "Train on 654 samples, validate on 73 samples\n",
      "Epoch 1/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 14.9947 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 12.0138 - acc: 0.0000e+00 - val_loss: 11.8707 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 10.3946 - acc: 0.0000e+00 - val_loss: 9.8287 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 9.7580 - acc: 0.0000e+00 - val_loss: 8.5847 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 9.1227 - acc: 0.0000e+00 - val_loss: 7.7794 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 8.2578 - acc: 0.0031 - val_loss: 6.9889 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 7.3121 - acc: 0.0856 - val_loss: 6.0843 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 6.6878 - acc: 0.0917 - val_loss: 5.4352 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 6.1401 - acc: 0.1498 - val_loss: 4.7737 - val_acc: 0.5068\n",
      "Epoch 10/10\n",
      "654/654 [==============================] - 42s 64ms/step - loss: 5.5260 - acc: 0.2370 - val_loss: 4.3205 - val_acc: 0.5205\n",
      "csv_num:54\n",
      "(548, 299, 299, 3)\n",
      "Train on 493 samples, validate on 55 samples\n",
      "Epoch 1/10\n",
      "493/493 [==============================] - 32s 66ms/step - loss: 12.5975 - acc: 0.0000e+00 - val_loss: 11.6604 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 11.0479 - acc: 0.0000e+00 - val_loss: 10.5294 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 10.5073 - acc: 0.0000e+00 - val_loss: 10.3095 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 10.0704 - acc: 0.0000e+00 - val_loss: 9.5807 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 9.7117 - acc: 0.0000e+00 - val_loss: 8.9060 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 9.0510 - acc: 0.0000e+00 - val_loss: 8.2439 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 8.5240 - acc: 0.0041 - val_loss: 7.7426 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 8.0143 - acc: 0.0162 - val_loss: 7.1490 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 7.5046 - acc: 0.0467 - val_loss: 6.2739 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "493/493 [==============================] - 32s 64ms/step - loss: 7.3525 - acc: 0.0751 - val_loss: 5.9836 - val_acc: 0.0000e+00\n",
      "csv_num:55\n",
      "(1072, 299, 299, 3)\n",
      "Train on 964 samples, validate on 108 samples\n",
      "Epoch 1/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 11.7557 - acc: 0.0000e+00 - val_loss: 10.1268 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 9.5824 - acc: 0.0031 - val_loss: 8.0231 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 7.7127 - acc: 0.0996 - val_loss: 6.9736 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 6.5752 - acc: 0.1639 - val_loss: 5.4869 - val_acc: 0.3796\n",
      "Epoch 5/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 5.5657 - acc: 0.2075 - val_loss: 3.5054 - val_acc: 0.4074\n",
      "Epoch 6/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 4.7978 - acc: 0.2718 - val_loss: 2.5910 - val_acc: 0.4074\n",
      "Epoch 7/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 4.7409 - acc: 0.2614 - val_loss: 2.3319 - val_acc: 0.4074\n",
      "Epoch 8/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 4.2136 - acc: 0.3029 - val_loss: 2.2846 - val_acc: 0.4074\n",
      "Epoch 9/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 4.1218 - acc: 0.3133 - val_loss: 2.3007 - val_acc: 0.4074\n",
      "Epoch 10/10\n",
      "964/964 [==============================] - 62s 64ms/step - loss: 3.8009 - acc: 0.3423 - val_loss: 2.7152 - val_acc: 0.3981\n",
      "csv_num:56\n",
      "(546, 299, 299, 3)\n",
      "Train on 491 samples, validate on 55 samples\n",
      "Epoch 1/10\n",
      "491/491 [==============================] - 33s 66ms/step - loss: 13.9438 - acc: 0.0000e+00 - val_loss: 12.2634 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 11.0952 - acc: 0.0000e+00 - val_loss: 9.9542 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 10.0211 - acc: 0.0000e+00 - val_loss: 8.9938 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 8.9506 - acc: 0.0020 - val_loss: 7.6241 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 8.0292 - acc: 0.0244 - val_loss: 6.3139 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 6.7054 - acc: 0.0570 - val_loss: 4.9053 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 6.0129 - acc: 0.0876 - val_loss: 3.8641 - val_acc: 0.1636\n",
      "Epoch 8/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 5.4828 - acc: 0.1079 - val_loss: 3.4471 - val_acc: 0.2909\n",
      "Epoch 9/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 5.0252 - acc: 0.1365 - val_loss: 3.4651 - val_acc: 0.2545\n",
      "Epoch 10/10\n",
      "491/491 [==============================] - 32s 64ms/step - loss: 4.8230 - acc: 0.1446 - val_loss: 3.5566 - val_acc: 0.2545\n",
      "csv_num:57\n",
      "(1262, 299, 299, 3)\n",
      "Train on 1135 samples, validate on 127 samples\n",
      "Epoch 1/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 12.1413 - acc: 0.0000e+00 - val_loss: 9.9443 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 9.7424 - acc: 0.0000e+00 - val_loss: 8.3502 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 8.1280 - acc: 0.0194 - val_loss: 7.2653 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 6.2912 - acc: 0.1242 - val_loss: 5.5123 - val_acc: 0.3543\n",
      "Epoch 5/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 5.3720 - acc: 0.2026 - val_loss: 3.4515 - val_acc: 0.3543\n",
      "Epoch 6/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 4.7458 - acc: 0.2220 - val_loss: 3.0435 - val_acc: 0.3543\n",
      "Epoch 7/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 4.2529 - acc: 0.2652 - val_loss: 3.2337 - val_acc: 0.3622\n",
      "Epoch 8/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 4.0585 - acc: 0.3004 - val_loss: 2.8240 - val_acc: 0.3701\n",
      "Epoch 9/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 3.8665 - acc: 0.3048 - val_loss: 2.6033 - val_acc: 0.3701\n",
      "Epoch 10/10\n",
      "1135/1135 [==============================] - 73s 64ms/step - loss: 3.7895 - acc: 0.3233 - val_loss: 2.6193 - val_acc: 0.3701\n",
      "csv_num:58\n",
      "(675, 299, 299, 3)\n",
      "Train on 607 samples, validate on 68 samples\n",
      "Epoch 1/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 14.9049 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 12.5788 - acc: 0.0000e+00 - val_loss: 13.0469 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 10.9808 - acc: 0.0000e+00 - val_loss: 10.3924 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 10.3479 - acc: 0.0000e+00 - val_loss: 9.4208 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 9.8136 - acc: 0.0000e+00 - val_loss: 8.9214 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 9.2952 - acc: 0.0000e+00 - val_loss: 8.7314 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 8.8158 - acc: 0.0000e+00 - val_loss: 7.3222 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 8.0378 - acc: 0.0066 - val_loss: 6.6080 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 7.1810 - acc: 0.0527 - val_loss: 5.8194 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "607/607 [==============================] - 39s 64ms/step - loss: 6.7130 - acc: 0.0791 - val_loss: 5.4534 - val_acc: 0.0000e+00\n",
      "csv_num:59\n",
      "(860, 299, 299, 3)\n",
      "Train on 774 samples, validate on 86 samples\n",
      "Epoch 1/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 12.0214 - acc: 0.0000e+00 - val_loss: 10.2836 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 10.1927 - acc: 0.0000e+00 - val_loss: 8.8674 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 9.0289 - acc: 0.0594 - val_loss: 7.5160 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 7.6303 - acc: 0.1098 - val_loss: 7.3931 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 6.7879 - acc: 0.1473 - val_loss: 5.8128 - val_acc: 0.5000\n",
      "Epoch 6/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 5.8689 - acc: 0.2287 - val_loss: 3.9326 - val_acc: 0.5349\n",
      "Epoch 7/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 5.2202 - acc: 0.2726 - val_loss: 3.1297 - val_acc: 0.5349\n",
      "Epoch 8/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 4.6220 - acc: 0.3385 - val_loss: 4.3122 - val_acc: 0.5000\n",
      "Epoch 9/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 4.4213 - acc: 0.3514 - val_loss: 2.8440 - val_acc: 0.5349\n",
      "Epoch 10/10\n",
      "774/774 [==============================] - 50s 64ms/step - loss: 4.1839 - acc: 0.3773 - val_loss: 2.6776 - val_acc: 0.5349\n",
      "csv_num:60\n",
      "(2384, 299, 299, 3)\n",
      "Train on 2145 samples, validate on 239 samples\n",
      "Epoch 1/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 11.6518 - acc: 0.0000e+00 - val_loss: 8.1799 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 7.6069 - acc: 0.0779 - val_loss: 4.4660 - val_acc: 0.0042\n",
      "Epoch 3/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 5.6912 - acc: 0.2047 - val_loss: 2.8101 - val_acc: 0.4644\n",
      "Epoch 4/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 4.7076 - acc: 0.2592 - val_loss: 2.6761 - val_acc: 0.4728\n",
      "Epoch 5/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 4.1393 - acc: 0.3203 - val_loss: 2.4345 - val_acc: 0.4644\n",
      "Epoch 6/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 3.7766 - acc: 0.3441 - val_loss: 2.4371 - val_acc: 0.4644\n",
      "Epoch 7/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 3.5613 - acc: 0.3660 - val_loss: 2.3289 - val_acc: 0.4644\n",
      "Epoch 8/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 3.5090 - acc: 0.3566 - val_loss: 2.0233 - val_acc: 0.4770\n",
      "Epoch 9/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 3.3915 - acc: 0.3669 - val_loss: 2.4900 - val_acc: 0.4477\n",
      "Epoch 10/10\n",
      "2145/2145 [==============================] - 138s 64ms/step - loss: 3.2698 - acc: 0.3692 - val_loss: 2.3562 - val_acc: 0.4561\n",
      "(373, 299, 299, 3)\n",
      "Train on 335 samples, validate on 38 samples\n",
      "Epoch 1/10\n",
      "335/335 [==============================] - 21s 64ms/step - loss: 3.0897 - acc: 0.3582 - val_loss: 3.0648 - val_acc: 0.4211\n",
      "Epoch 2/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.1253 - acc: 0.3672 - val_loss: 3.0409 - val_acc: 0.4211\n",
      "Epoch 3/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.0912 - acc: 0.3851 - val_loss: 3.0566 - val_acc: 0.4211\n",
      "Epoch 4/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.1056 - acc: 0.3851 - val_loss: 3.0645 - val_acc: 0.4211\n",
      "Epoch 5/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 2.8791 - acc: 0.4090 - val_loss: 3.0768 - val_acc: 0.4211\n",
      "Epoch 6/10\n",
      "335/335 [==============================] - 21s 64ms/step - loss: 3.0849 - acc: 0.3881 - val_loss: 3.0750 - val_acc: 0.3947\n",
      "Epoch 7/10\n",
      "335/335 [==============================] - 21s 64ms/step - loss: 3.0110 - acc: 0.3701 - val_loss: 3.1005 - val_acc: 0.4737\n",
      "Epoch 8/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.0863 - acc: 0.3910 - val_loss: 3.1078 - val_acc: 0.4474\n",
      "Epoch 9/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.0275 - acc: 0.4030 - val_loss: 3.1108 - val_acc: 0.4474\n",
      "Epoch 10/10\n",
      "335/335 [==============================] - 22s 64ms/step - loss: 3.0185 - acc: 0.4060 - val_loss: 3.1224 - val_acc: 0.4474\n",
      "csv_num:61\n",
      "(1261, 299, 299, 3)\n",
      "Train on 1134 samples, validate on 127 samples\n",
      "Epoch 1/10\n",
      "1134/1134 [==============================] - 72s 64ms/step - loss: 15.1622 - acc: 0.0000e+00 - val_loss: 14.8982 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 9.3009 - acc: 0.0406 - val_loss: 7.1880 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 4.7495 - acc: 0.4330 - val_loss: 2.4030 - val_acc: 0.6535\n",
      "Epoch 4/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 3.7951 - acc: 0.5194 - val_loss: 2.4670 - val_acc: 0.6457\n",
      "Epoch 5/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 3.3320 - acc: 0.5485 - val_loss: 3.5423 - val_acc: 0.5984\n",
      "Epoch 6/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 3.0594 - acc: 0.5661 - val_loss: 3.2214 - val_acc: 0.6063\n",
      "Epoch 7/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 2.9542 - acc: 0.5653 - val_loss: 2.2009 - val_acc: 0.6457\n",
      "Epoch 8/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 2.8010 - acc: 0.5794 - val_loss: 2.0855 - val_acc: 0.6457\n",
      "Epoch 9/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 2.7977 - acc: 0.5714 - val_loss: 3.1169 - val_acc: 0.5984\n",
      "Epoch 10/10\n",
      "1134/1134 [==============================] - 73s 64ms/step - loss: 2.8097 - acc: 0.5714 - val_loss: 2.5728 - val_acc: 0.6142\n",
      "csv_num:62\n",
      "(1383, 299, 299, 3)\n",
      "Train on 1244 samples, validate on 139 samples\n",
      "Epoch 1/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 12.6112 - acc: 0.0000e+00 - val_loss: 10.5291 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 7.2664 - acc: 0.0884 - val_loss: 5.3016 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 4.8454 - acc: 0.3320 - val_loss: 3.0956 - val_acc: 0.5612\n",
      "Epoch 4/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 4.1646 - acc: 0.3971 - val_loss: 2.6464 - val_acc: 0.5683\n",
      "Epoch 5/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.8054 - acc: 0.4317 - val_loss: 2.4865 - val_acc: 0.5683\n",
      "Epoch 6/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.4377 - acc: 0.4703 - val_loss: 2.4530 - val_acc: 0.5683\n",
      "Epoch 7/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.4197 - acc: 0.4767 - val_loss: 2.1427 - val_acc: 0.5755\n",
      "Epoch 8/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.2922 - acc: 0.4847 - val_loss: 2.4109 - val_acc: 0.5755\n",
      "Epoch 9/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.1774 - acc: 0.4831 - val_loss: 2.5069 - val_acc: 0.5683\n",
      "Epoch 10/10\n",
      "1244/1244 [==============================] - 80s 64ms/step - loss: 3.1283 - acc: 0.4936 - val_loss: 2.6120 - val_acc: 0.5612\n",
      "csv_num:63\n",
      "(890, 299, 299, 3)\n",
      "Train on 801 samples, validate on 89 samples\n",
      "Epoch 1/10\n",
      "801/801 [==============================] - 51s 64ms/step - loss: 14.8528 - acc: 0.0000e+00 - val_loss: 15.5089 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 10.0419 - acc: 0.0000e+00 - val_loss: 9.8332 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 7.7982 - acc: 0.0275 - val_loss: 6.9055 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 5.7255 - acc: 0.2260 - val_loss: 4.3455 - val_acc: 0.6629\n",
      "Epoch 5/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 4.4377 - acc: 0.4669 - val_loss: 3.7656 - val_acc: 0.6854\n",
      "Epoch 6/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 3.8710 - acc: 0.5918 - val_loss: 3.7804 - val_acc: 0.6742\n",
      "Epoch 7/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 3.6033 - acc: 0.6417 - val_loss: 3.6639 - val_acc: 0.6742\n",
      "Epoch 8/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 3.4313 - acc: 0.6529 - val_loss: 3.7388 - val_acc: 0.6742\n",
      "Epoch 9/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 3.2720 - acc: 0.6654 - val_loss: 2.9971 - val_acc: 0.6966\n",
      "Epoch 10/10\n",
      "801/801 [==============================] - 52s 64ms/step - loss: 3.2436 - acc: 0.6742 - val_loss: 2.3953 - val_acc: 0.7191\n",
      "csv_num:64\n",
      "(1450, 299, 299, 3)\n",
      "Train on 1305 samples, validate on 145 samples\n",
      "Epoch 1/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 11.8440 - acc: 0.0000e+00 - val_loss: 7.7914 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 6.0307 - acc: 0.1157 - val_loss: 2.5439 - val_acc: 0.3310\n",
      "Epoch 3/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 4.1980 - acc: 0.1977 - val_loss: 2.6240 - val_acc: 0.3310\n",
      "Epoch 4/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.8167 - acc: 0.2444 - val_loss: 3.1917 - val_acc: 0.3172\n",
      "Epoch 5/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.6286 - acc: 0.2429 - val_loss: 2.5916 - val_acc: 0.3310\n",
      "Epoch 6/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.4663 - acc: 0.2506 - val_loss: 3.1843 - val_acc: 0.3034\n",
      "Epoch 7/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.4638 - acc: 0.2598 - val_loss: 2.7945 - val_acc: 0.3241\n",
      "Epoch 8/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.3653 - acc: 0.2621 - val_loss: 2.7665 - val_acc: 0.3241\n",
      "Epoch 9/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.3345 - acc: 0.2598 - val_loss: 2.2690 - val_acc: 0.3310\n",
      "Epoch 10/10\n",
      "1305/1305 [==============================] - 84s 64ms/step - loss: 3.3196 - acc: 0.2751 - val_loss: 3.0296 - val_acc: 0.3241\n",
      "csv_num:65\n",
      "(1897, 299, 299, 3)\n",
      "Train on 1707 samples, validate on 190 samples\n",
      "Epoch 1/10\n",
      "1707/1707 [==============================] - 109s 64ms/step - loss: 12.0576 - acc: 0.0000e+00 - val_loss: 8.9020 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1707/1707 [==============================] - 110s 64ms/step - loss: 7.7858 - acc: 0.0293 - val_loss: 4.8360 - val_acc: 0.0105\n",
      "Epoch 3/10\n",
      "1707/1707 [==============================] - 110s 64ms/step - loss: 5.1306 - acc: 0.3269 - val_loss: 3.1544 - val_acc: 0.5421\n",
      "Epoch 4/10\n",
      "1707/1707 [==============================] - 110s 64ms/step - loss: 4.1025 - acc: 0.4446 - val_loss: 3.0457 - val_acc: 0.5316\n",
      "Epoch 5/10\n",
      "1707/1707 [==============================] - 109s 64ms/step - loss: 3.8110 - acc: 0.4634 - val_loss: 3.9725 - val_acc: 0.4632\n",
      "Epoch 6/10\n",
      "1707/1707 [==============================] - 109s 64ms/step - loss: 3.6031 - acc: 0.4687 - val_loss: 2.6813 - val_acc: 0.5421\n",
      "Epoch 7/10\n",
      "1707/1707 [==============================] - 109s 64ms/step - loss: 3.3175 - acc: 0.4956 - val_loss: 2.8016 - val_acc: 0.5263\n",
      "Epoch 8/10\n",
      "1707/1707 [==============================] - 109s 64ms/step - loss: 3.2117 - acc: 0.4933 - val_loss: 2.4372 - val_acc: 0.5421\n",
      "Epoch 9/10\n",
      "1707/1707 [==============================] - 110s 64ms/step - loss: 3.1238 - acc: 0.4968 - val_loss: 1.9177 - val_acc: 0.5684\n",
      "Epoch 10/10\n",
      "1707/1707 [==============================] - 110s 64ms/step - loss: 3.0196 - acc: 0.5056 - val_loss: 2.4588 - val_acc: 0.5316\n",
      "csv_num:66\n",
      "(382, 299, 299, 3)\n",
      "Train on 343 samples, validate on 39 samples\n",
      "Epoch 1/10\n",
      "343/343 [==============================] - 22s 64ms/step - loss: 15.5569 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 13.8558 - acc: 0.0000e+00 - val_loss: 15.8401 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 11.7562 - acc: 0.0000e+00 - val_loss: 12.5791 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 10.9991 - acc: 0.0000e+00 - val_loss: 10.9904 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 10.3122 - acc: 0.0000e+00 - val_loss: 10.0930 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 9.7479 - acc: 0.0000e+00 - val_loss: 9.3043 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 22s 65ms/step - loss: 9.0232 - acc: 0.0000e+00 - val_loss: 8.6536 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 8.5104 - acc: 0.0000e+00 - val_loss: 7.7487 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "343/343 [==============================] - 22s 65ms/step - loss: 8.0615 - acc: 0.0029 - val_loss: 7.0957 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "343/343 [==============================] - 22s 64ms/step - loss: 7.5770 - acc: 0.0146 - val_loss: 6.3255 - val_acc: 0.0000e+00\n",
      "csv_num:67\n",
      "(1787, 299, 299, 3)\n",
      "Train on 1608 samples, validate on 179 samples\n",
      "Epoch 1/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 11.4972 - acc: 0.0000e+00 - val_loss: 9.7393 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 9.0369 - acc: 6.2189e-04 - val_loss: 6.6602 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 7.0549 - acc: 0.0373 - val_loss: 3.6990 - val_acc: 0.2458\n",
      "Epoch 4/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 5.7482 - acc: 0.0995 - val_loss: 2.9587 - val_acc: 0.2458\n",
      "Epoch 5/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 4.9279 - acc: 0.1381 - val_loss: 2.9718 - val_acc: 0.2402\n",
      "Epoch 6/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 4.5997 - acc: 0.1567 - val_loss: 3.0095 - val_acc: 0.2346\n",
      "Epoch 7/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 4.3125 - acc: 0.1517 - val_loss: 3.0580 - val_acc: 0.2402\n",
      "Epoch 8/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 4.1026 - acc: 0.1928 - val_loss: 3.1850 - val_acc: 0.2458\n",
      "Epoch 9/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 3.9009 - acc: 0.2065 - val_loss: 3.1021 - val_acc: 0.2458\n",
      "Epoch 10/10\n",
      "1608/1608 [==============================] - 103s 64ms/step - loss: 3.9393 - acc: 0.2139 - val_loss: 2.9984 - val_acc: 0.2458\n",
      "csv_num:68\n",
      "(626, 299, 299, 3)\n",
      "Train on 563 samples, validate on 63 samples\n",
      "Epoch 1/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 15.5178 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 14.4309 - acc: 0.0000e+00 - val_loss: 14.0007 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 11.8488 - acc: 0.0000e+00 - val_loss: 11.0390 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 10.9747 - acc: 0.0000e+00 - val_loss: 10.1526 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 10.3850 - acc: 0.0000e+00 - val_loss: 9.4306 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 9.5698 - acc: 0.0000e+00 - val_loss: 8.5126 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 8.8086 - acc: 0.0053 - val_loss: 7.3466 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 7.7631 - acc: 0.0337 - val_loss: 6.5733 - val_acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 7.0566 - acc: 0.0568 - val_loss: 6.2644 - val_acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "563/563 [==============================] - 36s 64ms/step - loss: 5.9513 - acc: 0.1403 - val_loss: 5.5733 - val_acc: 0.2063\n",
      "csv_num:69\n",
      "(2002, 299, 299, 3)\n",
      "Train on 1801 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 11.2265 - acc: 5.5525e-04 - val_loss: 9.5266 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 7.6747 - acc: 0.0805 - val_loss: 5.3117 - val_acc: 0.2836\n",
      "Epoch 3/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 5.6890 - acc: 0.1799 - val_loss: 3.3860 - val_acc: 0.2886\n",
      "Epoch 4/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 4.9923 - acc: 0.2210 - val_loss: 3.1901 - val_acc: 0.2886\n",
      "Epoch 5/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 4.4084 - acc: 0.2515 - val_loss: 3.1345 - val_acc: 0.2886\n",
      "Epoch 6/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 4.0307 - acc: 0.2760 - val_loss: 2.5360 - val_acc: 0.2786\n",
      "Epoch 7/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 3.8504 - acc: 0.2898 - val_loss: 3.2974 - val_acc: 0.2836\n",
      "Epoch 8/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 3.6365 - acc: 0.2954 - val_loss: 3.1543 - val_acc: 0.2836\n",
      "Epoch 9/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 3.4874 - acc: 0.3082 - val_loss: 2.8448 - val_acc: 0.2836\n",
      "Epoch 10/10\n",
      "1801/1801 [==============================] - 116s 64ms/step - loss: 3.4508 - acc: 0.3265 - val_loss: 2.8882 - val_acc: 0.2886\n",
      "csv_num:70\n",
      "(1290, 299, 299, 3)\n",
      "Train on 1161 samples, validate on 129 samples\n",
      "Epoch 1/10\n",
      "1161/1161 [==============================] - 74s 64ms/step - loss: 14.1934 - acc: 0.0000e+00 - val_loss: 13.8214 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 10.9492 - acc: 0.0000e+00 - val_loss: 9.1842 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 9.0915 - acc: 8.6133e-04 - val_loss: 7.2035 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 7.4906 - acc: 0.0827 - val_loss: 5.5574 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 6.3831 - acc: 0.2041 - val_loss: 4.1547 - val_acc: 0.5969\n",
      "Epoch 6/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 5.5480 - acc: 0.2696 - val_loss: 3.4976 - val_acc: 0.5969\n",
      "Epoch 7/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 4.9137 - acc: 0.3488 - val_loss: 3.0768 - val_acc: 0.5969\n",
      "Epoch 8/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 4.4290 - acc: 0.3876 - val_loss: 2.9411 - val_acc: 0.5891\n",
      "Epoch 9/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 4.2115 - acc: 0.4186 - val_loss: 2.8519 - val_acc: 0.5969\n",
      "Epoch 10/10\n",
      "1161/1161 [==============================] - 75s 64ms/step - loss: 3.9821 - acc: 0.4255 - val_loss: 2.6841 - val_acc: 0.6047\n",
      "csv_num:71\n",
      "(921, 299, 299, 3)\n",
      "Train on 828 samples, validate on 93 samples\n",
      "Epoch 1/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 14.9238 - acc: 0.0000e+00 - val_loss: 14.8046 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 12.2408 - acc: 0.0000e+00 - val_loss: 11.3684 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 11.0556 - acc: 0.0000e+00 - val_loss: 10.3500 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 10.3837 - acc: 0.0000e+00 - val_loss: 9.5566 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 9.6816 - acc: 0.0000e+00 - val_loss: 8.8137 - val_acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 8.5866 - acc: 0.0048 - val_loss: 6.7939 - val_acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 7.2062 - acc: 0.0592 - val_loss: 5.3531 - val_acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 6.2783 - acc: 0.1196 - val_loss: 4.3680 - val_acc: 0.2796\n",
      "Epoch 9/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 5.8525 - acc: 0.1486 - val_loss: 3.4980 - val_acc: 0.2796\n",
      "Epoch 10/10\n",
      "828/828 [==============================] - 53s 64ms/step - loss: 5.2347 - acc: 0.1727 - val_loss: 3.3530 - val_acc: 0.2688\n",
      "csv_num:72\n",
      "(1080, 299, 299, 3)\n",
      "Train on 972 samples, validate on 108 samples\n",
      "Epoch 1/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 12.9427 - acc: 0.0000e+00 - val_loss: 10.6810 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 10.3394 - acc: 0.0000e+00 - val_loss: 8.7417 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 9.0522 - acc: 0.0514 - val_loss: 7.2677 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 7.8931 - acc: 0.0905 - val_loss: 5.8509 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 7.0857 - acc: 0.0936 - val_loss: 4.6446 - val_acc: 0.4074\n",
      "Epoch 6/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 6.5644 - acc: 0.1368 - val_loss: 3.6340 - val_acc: 0.4167\n",
      "Epoch 7/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 5.9335 - acc: 0.1636 - val_loss: 2.8072 - val_acc: 0.4352\n",
      "Epoch 8/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 5.4871 - acc: 0.1955 - val_loss: 2.2931 - val_acc: 0.4444\n",
      "Epoch 9/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 5.1296 - acc: 0.2315 - val_loss: 2.8500 - val_acc: 0.4259\n",
      "Epoch 10/10\n",
      "972/972 [==============================] - 62s 64ms/step - loss: 4.9433 - acc: 0.2181 - val_loss: 3.8665 - val_acc: 0.3796\n",
      "csv_num:73\n",
      "(2188, 299, 299, 3)\n",
      "Train on 1969 samples, validate on 219 samples\n",
      "Epoch 1/10\n",
      "1969/1969 [==============================] - 126s 64ms/step - loss: 12.4801 - acc: 0.0000e+00 - val_loss: 9.7553 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 9.3415 - acc: 0.0091 - val_loss: 6.7075 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 6.8724 - acc: 0.1661 - val_loss: 3.8765 - val_acc: 0.6256\n",
      "Epoch 4/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 5.4241 - acc: 0.3002 - val_loss: 3.0536 - val_acc: 0.6073\n",
      "Epoch 5/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 4.8075 - acc: 0.3550 - val_loss: 2.5225 - val_acc: 0.6256\n",
      "Epoch 6/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 4.2537 - acc: 0.3972 - val_loss: 2.2401 - val_acc: 0.6393\n",
      "Epoch 7/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 3.9563 - acc: 0.4332 - val_loss: 2.4514 - val_acc: 0.6393\n",
      "Epoch 8/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 3.6907 - acc: 0.4820 - val_loss: 2.1867 - val_acc: 0.6438\n",
      "Epoch 9/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 3.4141 - acc: 0.5201 - val_loss: 1.7858 - val_acc: 0.6530\n",
      "Epoch 10/10\n",
      "1969/1969 [==============================] - 127s 64ms/step - loss: 3.3336 - acc: 0.5287 - val_loss: 2.1337 - val_acc: 0.6393\n",
      "csv_num:74\n",
      "(927, 299, 299, 3)\n",
      "Train on 834 samples, validate on 93 samples\n",
      "Epoch 1/10\n",
      "834/834 [==============================] - 54s 65ms/step - loss: 15.3109 - acc: 0.0000e+00 - val_loss: 16.1181 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 12.2917 - acc: 0.0000e+00 - val_loss: 9.5487 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 9.4297 - acc: 0.0024 - val_loss: 5.9910 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 7.7004 - acc: 0.0528 - val_loss: 4.4020 - val_acc: 0.2688\n",
      "Epoch 5/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 6.5982 - acc: 0.0624 - val_loss: 3.8497 - val_acc: 0.2688\n",
      "Epoch 6/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 5.7222 - acc: 0.1127 - val_loss: 4.1993 - val_acc: 0.2688\n",
      "Epoch 7/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 5.3310 - acc: 0.1223 - val_loss: 3.1670 - val_acc: 0.2688\n",
      "Epoch 8/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 5.1058 - acc: 0.1247 - val_loss: 3.2844 - val_acc: 0.2688\n",
      "Epoch 9/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 4.9915 - acc: 0.1379 - val_loss: 3.5829 - val_acc: 0.2688\n",
      "Epoch 10/10\n",
      "834/834 [==============================] - 54s 64ms/step - loss: 4.6309 - acc: 0.1679 - val_loss: 3.5273 - val_acc: 0.2688\n",
      "csv_num:75\n",
      "(1539, 299, 299, 3)\n",
      "Train on 1385 samples, validate on 154 samples\n",
      "Epoch 1/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 13.0502 - acc: 0.0000e+00 - val_loss: 10.0667 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 9.0930 - acc: 0.0209 - val_loss: 7.1629 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 7.1352 - acc: 0.1047 - val_loss: 4.7975 - val_acc: 0.2727\n",
      "Epoch 4/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 5.8592 - acc: 0.1112 - val_loss: 3.2358 - val_acc: 0.2727\n",
      "Epoch 5/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 5.1309 - acc: 0.1538 - val_loss: 3.0577 - val_acc: 0.2857\n",
      "Epoch 6/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 4.7447 - acc: 0.1856 - val_loss: 3.0959 - val_acc: 0.2662\n",
      "Epoch 7/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 4.4279 - acc: 0.2014 - val_loss: 3.0096 - val_acc: 0.2922\n",
      "Epoch 8/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 4.2926 - acc: 0.1935 - val_loss: 2.8894 - val_acc: 0.2857\n",
      "Epoch 9/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 4.0661 - acc: 0.2209 - val_loss: 2.5703 - val_acc: 0.2922\n",
      "Epoch 10/10\n",
      "1385/1385 [==============================] - 89s 64ms/step - loss: 3.9985 - acc: 0.2166 - val_loss: 2.6716 - val_acc: 0.2857\n",
      "csv_num:76\n",
      "(937, 299, 299, 3)\n",
      "Train on 843 samples, validate on 94 samples\n",
      "Epoch 1/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 14.9658 - acc: 0.0000e+00 - val_loss: 15.6445 - val_acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 12.3204 - acc: 0.0000e+00 - val_loss: 10.3781 - val_acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 10.4996 - acc: 0.0000e+00 - val_loss: 7.5739 - val_acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 8.9388 - acc: 0.0036 - val_loss: 4.8686 - val_acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 7.3081 - acc: 0.0581 - val_loss: 3.8271 - val_acc: 0.2021\n",
      "Epoch 6/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 6.0058 - acc: 0.0913 - val_loss: 4.0785 - val_acc: 0.1809\n",
      "Epoch 7/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 5.0968 - acc: 0.1269 - val_loss: 3.5061 - val_acc: 0.1915\n",
      "Epoch 8/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 4.6469 - acc: 0.1590 - val_loss: 4.2573 - val_acc: 0.1809\n",
      "Epoch 9/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 4.2570 - acc: 0.1554 - val_loss: 4.9623 - val_acc: 0.1702\n",
      "Epoch 10/10\n",
      "843/843 [==============================] - 54s 64ms/step - loss: 4.0913 - acc: 0.1661 - val_loss: 4.4366 - val_acc: 0.1915\n",
      "csv_num:77\n",
      "(2447, 299, 299, 3)\n",
      "Train on 2202 samples, validate on 245 samples\n",
      "Epoch 1/10\n",
      "2202/2202 [==============================] - 141s 64ms/step - loss: 9.4924 - acc: 0.0849 - val_loss: 2.9908 - val_acc: 0.7469\n",
      "Epoch 2/10\n",
      "2202/2202 [==============================] - 142s 64ms/step - loss: 2.9454 - acc: 0.6635 - val_loss: 1.4282 - val_acc: 0.7959\n",
      "Epoch 3/10\n",
      "2202/2202 [==============================] - 141s 64ms/step - loss: 2.0770 - acc: 0.7775 - val_loss: 2.0815 - val_acc: 0.7633\n",
      "Epoch 4/10\n",
      "2202/2202 [==============================] - 141s 64ms/step - loss: 1.9405 - acc: 0.7943 - val_loss: 1.9807 - val_acc: 0.7592\n",
      "Epoch 5/10\n",
      "2202/2202 [==============================] - 141s 64ms/step - loss: 1.8975 - acc: 0.8034 - val_loss: 1.7145 - val_acc: 0.7755\n",
      "Epoch 6/10\n",
      "2202/2202 [==============================] - 142s 64ms/step - loss: 1.9513 - acc: 0.7956 - val_loss: 0.9394 - val_acc: 0.8163\n",
      "Epoch 7/10\n",
      "2202/2202 [==============================] - 142s 64ms/step - loss: 1.9001 - acc: 0.8015 - val_loss: 1.7103 - val_acc: 0.7755\n",
      "Epoch 8/10\n",
      "2202/2202 [==============================] - 142s 64ms/step - loss: 1.9134 - acc: 0.8002 - val_loss: 1.6954 - val_acc: 0.7755\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2202/2202 [==============================] - 142s 64ms/step - loss: 1.8708 - acc: 0.7984 - val_loss: 1.0451 - val_acc: 0.8163\n",
      "Epoch 10/10\n",
      "2202/2202 [==============================] - 142s 64ms/step - loss: 1.8369 - acc: 0.8052 - val_loss: 1.3126 - val_acc: 0.8082\n",
      "(2207, 299, 299, 3)\n",
      "Train on 1986 samples, validate on 221 samples\n",
      "Epoch 1/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9356 - acc: 0.7860 - val_loss: 1.8415 - val_acc: 0.7466\n",
      "Epoch 2/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9303 - acc: 0.7875 - val_loss: 1.8387 - val_acc: 0.7466\n",
      "Epoch 3/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9060 - acc: 0.7905 - val_loss: 2.1232 - val_acc: 0.7330\n",
      "Epoch 4/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9267 - acc: 0.7815 - val_loss: 3.4020 - val_acc: 0.6606\n",
      "Epoch 5/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9246 - acc: 0.7805 - val_loss: 2.3990 - val_acc: 0.7149\n",
      "Epoch 6/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.9355 - acc: 0.7890 - val_loss: 1.7731 - val_acc: 0.7421\n",
      "Epoch 7/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.5026 - acc: 0.8061 - val_loss: 1.5264 - val_acc: 0.7692\n",
      "Epoch 8/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.1932 - acc: 0.8258 - val_loss: 1.4253 - val_acc: 0.7692\n",
      "Epoch 9/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.2049 - acc: 0.8308 - val_loss: 1.1881 - val_acc: 0.7692\n",
      "Epoch 10/10\n",
      "1986/1986 [==============================] - 128s 64ms/step - loss: 1.1721 - acc: 0.8313 - val_loss: 1.4193 - val_acc: 0.7692\n",
      "(2478, 299, 299, 3)\n",
      "Train on 2230 samples, validate on 248 samples\n",
      "Epoch 1/10\n",
      "2230/2230 [==============================] - 144s 65ms/step - loss: 1.1907 - acc: 0.8300 - val_loss: 0.9013 - val_acc: 0.8306\n",
      "Epoch 2/10\n",
      "2230/2230 [==============================] - 145s 65ms/step - loss: 1.1280 - acc: 0.8300 - val_loss: 0.8228 - val_acc: 0.8306\n",
      "Epoch 3/10\n",
      "2230/2230 [==============================] - 144s 65ms/step - loss: 1.1081 - acc: 0.8291 - val_loss: 0.8694 - val_acc: 0.8306\n",
      "Epoch 4/10\n",
      "2230/2230 [==============================] - 144s 65ms/step - loss: 1.0561 - acc: 0.8291 - val_loss: 0.9283 - val_acc: 0.8306\n",
      "Epoch 5/10\n",
      "2230/2230 [==============================] - 144s 64ms/step - loss: 1.0593 - acc: 0.8309 - val_loss: 0.7141 - val_acc: 0.8306\n",
      "Epoch 6/10\n",
      "2230/2230 [==============================] - 144s 64ms/step - loss: 1.1234 - acc: 0.8305 - val_loss: 0.7766 - val_acc: 0.8306\n",
      "Epoch 7/10\n",
      "2230/2230 [==============================] - 143s 64ms/step - loss: 1.0971 - acc: 0.8305 - val_loss: 0.9447 - val_acc: 0.8306\n",
      "Epoch 8/10\n",
      "2230/2230 [==============================] - 143s 64ms/step - loss: 1.0931 - acc: 0.8314 - val_loss: 0.8211 - val_acc: 0.8306\n",
      "Epoch 9/10\n",
      "1392/2230 [=================>............] - ETA: 51s - loss: 1.0873 - acc: 0.8125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-796eacc3b26a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m                     \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m14951\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "###################按label切分数据，每次训练20类：   以及尝试训练\n",
    "#####数据分析\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split #数据拆分\n",
    "from keras.utils import np_utils #编码器\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# import keras.backend.tensorflow_backend as KTF  \n",
    "# KTF.set_session(tf.Session(config=tf.ConfigProto(device_count={'gpu':0}))) \n",
    "\n",
    "from inception_v4 import create_inception_v4\n",
    "\n",
    "#model = create_inception_v4()\n",
    "model = load_model('temp.h5')\n",
    "#model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "#test_data = pd.read_csv('data/test.csv')\n",
    "file_dir=\"data/train_img/\"\n",
    "\n",
    "BATCH_SIZE=16 ##16\n",
    "lr_power = 0.9\n",
    "lr_base=0.001\n",
    "\n",
    "for epoch_time in range(0,20):\n",
    "    lr_now = lr_base * ((1 - float(epoch_time)/20) ** lr_power)\n",
    "    def_adam=Adam(lr=lr_now)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer=def_adam,metrics=['accuracy'])\n",
    "    \n",
    "    for file_num in range(77,748): #############14950/20  0-748,temp:32-748,77-,\n",
    "        train_csv_path=\"labels_split/train-%d.csv\"%(file_num)\n",
    "        train_data = pd.read_csv(train_csv_path)\n",
    "        \n",
    "        total_num=train_data.shape[0]\n",
    "        print(\"csv_num:%d\"%(file_num))\n",
    "        ifLarge=int(total_num/2500)\n",
    "        if(ifLarge==0):\n",
    "            images = []\n",
    "            labels = []\n",
    "\n",
    "            for img_num in range(0,total_num):\n",
    "                img_path=file_dir+train_data['id'][img_num]+\".jpg\"\n",
    "                if os.path.exists(img_path):\n",
    "                    im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "                    imResize = im.resize((299, 299))\n",
    "                    imageData = np.array(imResize)\n",
    "                    images.append(imageData)\n",
    "                    #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "                    labels.append(train_data['landmark_id'][img_num])\n",
    "\n",
    "\n",
    "            X = np.array(images)\n",
    "            y = np.array(labels)\n",
    "            print(X.shape)\n",
    "\n",
    "            if(X.shape[0]>1):\n",
    "                X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=30)\n",
    "\n",
    "                y_train = np_utils.to_categorical(y_train,14951) #矢量编码\n",
    "                y_test = np_utils.to_categorical(y_test,14951)\n",
    "\n",
    "                model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=BATCH_SIZE,verbose=1)\n",
    "        else:\n",
    "            img_num_low=0\n",
    "            img_num_high=0\n",
    "            for img_num_low in range(0,total_num-2499,2500):\n",
    "                img_num_high=img_num_low+2500\n",
    "                images = []\n",
    "                labels = []\n",
    "\n",
    "                for img_num in range(img_num_low,img_num_high):\n",
    "                    img_path=file_dir+train_data['id'][img_num]+\".jpg\"\n",
    "                    if os.path.exists(img_path):\n",
    "                        im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "                        imResize = im.resize((299, 299))\n",
    "                        imageData = np.array(imResize)\n",
    "                        images.append(imageData)\n",
    "                        #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "                        labels.append(train_data['landmark_id'][img_num])\n",
    "\n",
    "                X = np.array(images)\n",
    "                y = np.array(labels)\n",
    "                print(X.shape)\n",
    "\n",
    "                if(X.shape[0]>1):\n",
    "                    X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=30)\n",
    "\n",
    "                    y_train = np_utils.to_categorical(y_train,14951) #矢量编码\n",
    "                    y_test = np_utils.to_categorical(y_test,14951)\n",
    "\n",
    "                    model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=BATCH_SIZE,verbose=1)\n",
    "\n",
    "            images = []\n",
    "            labels = []  \n",
    "            for img_num in range(img_num_high,total_num):\n",
    "                img_path=file_dir+train_data['id'][img_num]+\".jpg\"\n",
    "                if os.path.exists(img_path):\n",
    "                    im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "                    imResize = im.resize((299, 299))\n",
    "                    imageData = np.array(imResize)\n",
    "                    images.append(imageData)\n",
    "                    #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "                    labels.append(train_data['landmark_id'][img_num])\n",
    "\n",
    "            X = np.array(images)\n",
    "            y = np.array(labels)\n",
    "            print(X.shape)\n",
    "\n",
    "            if(X.shape[0]>1):\n",
    "                X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=30)\n",
    "\n",
    "                y_train = np_utils.to_categorical(y_train,14951) #矢量编码\n",
    "                y_test = np_utils.to_categorical(y_test,14951)\n",
    "\n",
    "                model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=10,batch_size=16,verbose=1)\n",
    "                \n",
    "    \n",
    "        \n",
    "# images_array = np.array(images)\n",
    "# labels_array = np.array(labels)\n",
    "# X = np.array(images)\n",
    "# y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing\n",
    "# scores=model.evaluate(X_test,y_test,verbose=1)\n",
    "# print('Test score:', scores[0])\n",
    "# print('Test accuracy:', scores[1])\n",
    "\n",
    "# #model.save('edge_model2_random.h5')\n",
    "#model.save('temp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "7\n",
      "14\n",
      "28\n",
      "67\n",
      "134\n",
      "268\n",
      "469\n",
      "653\n",
      "938\n",
      "1306\n",
      "1876\n",
      "2612\n",
      "4571\n",
      "9142\n",
      "18284\n",
      "43751\n",
      "87502\n",
      "175004\n",
      "306257\n",
      "612514\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,1225028):\n",
    "    if(1225028%i==0):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), strides=(1, 1), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:42: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\")`\n",
      "  x1 = MaxPooling2D((3, 3), strides=(2, 2), border_mode='valid')(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:45: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  x = merge([x1, x2], mode='concat', concat_axis=channel_axis)\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:465: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), strides=(1, 1), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (1, 7), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (7, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:55: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  x = merge([x1, x2], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:58: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\")`\n",
      "  x2 = MaxPooling2D((3, 3), strides=(2, 2), border_mode='valid')(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:60: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  x = merge([x1, x2], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(96, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:79: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((3, 3), strides=(1, 1), padding=\"same\")`\n",
      "  a4 = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(input)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:82: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  m = merge([a1, a2, a3, a4], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(224, (3, 3), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:150: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\")`\n",
      "  r3 = MaxPooling2D((3, 3), strides=(2, 2), border_mode='valid')(input)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:152: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  m = merge([r1, r2, r3], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(224, (1, 7), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (7, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(192, (7, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(224, (7, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 7), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:104: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((3, 3), strides=(1, 1), padding=\"same\")`\n",
      "  b4 = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(input)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:107: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  m = merge([b1, b2, b3, b4], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(320, (7, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(320, (3, 3), strides=(2, 2), padding=\"valid\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:170: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D((3, 3), strides=(2, 2), padding=\"valid\")`\n",
      "  r3 = MaxPooling2D((3, 3), strides=(2, 2), border_mode='valid')(input)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:172: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  m = merge([r1, r2, r3], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (1, 3), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:122: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  c2 = merge([c2_1, c2_2], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(448, (3, 1), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:25: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 3), strides=(1, 1), padding=\"same\", use_bias=False)`\n",
      "  x = Convolution2D(nb_filter, nb_row, nb_col, subsample=subsample, border_mode=border_mode, bias=bias)(x)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:129: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  c3 = merge([c3_1, c3_2], mode='concat', concat_axis=channel_axis)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:131: UserWarning: Update your `AveragePooling2D` call to the Keras 2 API: `AveragePooling2D((3, 3), strides=(1, 1), padding=\"same\")`\n",
      "  c4 = AveragePooling2D((3, 3), strides=(1, 1), border_mode='same')(input)\n",
      "/notebooks/GoogleLandmarkRec/inception_v4.py:134: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  m = merge([c1, c2, c3, c4], mode='concat', concat_axis=channel_axis)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model weights loaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/GoogleLandmarkRec/inception_v4.py:218: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=14951, activation=\"softmax\")`\n",
      "  out = Dense(output_dim=nb_classes, activation='softmax')(x)\n"
     ]
    }
   ],
   "source": [
    "from inception_v4 import create_inception_v4\n",
    "\n",
    "model = create_inception_v4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from keras.utils import np_utils #编码器\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "file_dir=\"data/train_img/\"\n",
    "\n",
    "labels =[]\n",
    "for img_num in range(0,100,1):\n",
    "    img_path=file_dir+train_data['id'][img_num]+\".jpg\"\n",
    "    if os.path.exists(img_path):\n",
    "        im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "        #imResize = im.resize((299, 299))\n",
    "        #imageData = np.array(imResize)\n",
    "        #images.append(imageData)\n",
    "        #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "        labels.append(train_data['landmark_id'][img_num])\n",
    "\n",
    "#X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "y_test = np_utils.to_categorical(y,14951)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4676,  6651, 11284,  8429,  6231, 10400,  9779, 11288, 13170,\n",
       "        6051,  8302,  3903, 11702,  6347,   691,  9633,  9633,  9633,\n",
       "        7794,  9779,  4645,  2743,  4135,  6051,  6051,  2949,  4981,\n",
       "        2427,  3457,  7615,  6051,  6707,  3724,  4987,  9633,  5140,\n",
       "        7975,  9633,  5023, 13341,  9633,  9633, 11541,  2272,  5762,\n",
       "        7058,  2743, 11254,  9633,  8395,  2743,  5985,  6685,  9633,\n",
       "        1966, 12210,  4793,   369,  8692,  3878, 12156,  2743, 12712,\n",
       "        3040,  6696,  7147,  2339,  7612,  9779,  3938,  4190, 12896,\n",
       "        6051,  7416,  2338,  6309, 11255, 10900,  7058,  9633, 13797,\n",
       "        2664,   148, 11247,  4352,  5554,  6523, 10600,  7033,  9633,\n",
       "        6051,  7790, 12336,  8896, 10025,  6956,   452,  1038, 11437])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1][6651]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
