{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import MaxPooling2D, Convolution2D, AveragePooling2D\n",
    "\n",
    "#base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(299,299,3),pooling='avg')\n",
    "base_model = keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, weights='imagenet',input_shape=(299,299,3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(384, (1, 1), activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"pr...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "x = base_model.output\n",
    "x = Convolution2D(384, 1, 1, activation='relu', border_mode='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "x = Dropout(0.8)(x)\n",
    "x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "x = Dropout(0.8)(x)\n",
    "predictions = Dense(228, activation='sigmoid', name='predictions')(x)\n",
    "\n",
    "model = Model(input=base_model.input, output=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################切分数据--1225029：   以及尝试训练\n",
    "#####数据分析\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf \n",
    "from sklearn.model_selection import train_test_split #数据拆分\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam,SGD\n",
    "\n",
    "#model = create_inception_v4()\n",
    "#model=create_inception_resnet_v2(nb_classes=228)\n",
    "#model.summary()\n",
    "#model = load_model('temp_vgg.h5')\n",
    "#model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('data/train.csv')   ####1014544\n",
    "val_data = pd.read_csv('data/val.csv')\n",
    "#test_data = pd.read_csv('data/test.csv')\n",
    "file_dir=\"data/train_data/\"\n",
    "val_dir=\"data/val_data/\"\n",
    "\n",
    "step=10047 ##2511,10047\n",
    "BATCH_SIZE=16 ##16,32\n",
    "lr_power = 0.9\n",
    "lr_base=0.001\n",
    "\n",
    "\n",
    "\n",
    "###########----------------------validationData\n",
    "images = []\n",
    "labels = []\n",
    "for img_num in range(0,3000):\n",
    "    img_name=val_data['filename'][img_num]\n",
    "    img_path = val_dir+img_name\n",
    "    if os.path.exists(img_path):\n",
    "        im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "        imResize = im.resize((299, 299))\n",
    "        imageData = np.array(imResize)\n",
    "        images.append(imageData)\n",
    "        #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "        #labels.append(train_data['landmark_id'][img_num])\n",
    "        temp=img_name.split(\"_\")\n",
    "        temp=temp[3].split(\".\")\n",
    "        temp=temp[0].split(\"[\")\n",
    "        temp=temp[1].split(\"]\")\n",
    "        temp=temp[0].split(\",\")\n",
    "\n",
    "        each_label_list = [0] * 228\n",
    "        for j in range(0,len(temp)):\n",
    "            each_label_list[int(temp[j])-1]=1\n",
    "\n",
    "        labels.append(each_label_list)\n",
    "\n",
    "X_val = np.array(images)\n",
    "X_val = X_val.reshape(X_val.shape[0],299,299,3).astype('float32')\n",
    "y_val=np.array(labels,dtype=np.float)\n",
    "\n",
    "###########------------------------------------------\n",
    "\n",
    "for epoch_t in range(0,20):\n",
    "    lr_now = lr_base * ((1 - float(epoch_t)/20) ** lr_power)\n",
    "    #def_adam=Adam(lr=lr_now)\n",
    "    optimizer = SGD(lr=lr_now, momentum=0.9)\n",
    "    model.compile(loss = 'binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])\n",
    "    \n",
    "    img_range_high=0\n",
    "    for img_range_low in range(0,1014544-step,step):\n",
    "        print(img_range_low)\n",
    "        img_range_high=img_range_low+step+1\n",
    "        images = []\n",
    "        labels = []\n",
    "\n",
    "        for img_num in range(img_range_low,img_range_high,1):\n",
    "            img_name=train_data['filename'][img_num]\n",
    "            img_path = \"data/train_data/\"+img_name\n",
    "            if os.path.exists(img_path):\n",
    "                im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "                imResize = im.resize((299, 299))\n",
    "                imageData = np.array(imResize)\n",
    "                images.append(imageData)\n",
    "                #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "                #labels.append(train_data['landmark_id'][img_num])\n",
    "                temp=img_name.split(\"_\")\n",
    "                temp=temp[3].split(\".\")\n",
    "                temp=temp[0].split(\"[\")\n",
    "                temp=temp[1].split(\"]\")\n",
    "                temp=temp[0].split(\",\")\n",
    "\n",
    "                each_label_list = [0] * 228\n",
    "                for j in range(0,len(temp)):\n",
    "                    each_label_list[int(temp[j])-1]=1\n",
    "\n",
    "                labels.append(each_label_list)\n",
    "\n",
    "        X = np.array(images)\n",
    "        y=np.array(labels,dtype=np.float)\n",
    "        print(X.shape)\n",
    "        \n",
    "        if(X.shape[0]>1):\n",
    "            X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "            #X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=30)\n",
    "\n",
    "            #y_train = np_utils.to_categorical(y_train,14951) #矢量编码\n",
    "            #y_test = np_utils.to_categorical(y_test,14951)\n",
    "\n",
    "            #model.fit(X,[y,y],epochs=1,batch_size=BATCH_SIZE,verbose=1)\n",
    "            model.fit(X,y,epochs=1,batch_size=BATCH_SIZE,verbose=1)\n",
    "            \n",
    "    ###使用最后的余留的数据\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img_num in range(img_range_high,1014544,1):\n",
    "        img_name=train_data['filename'][img_num]\n",
    "        img_path = \"data/train_data/\"+img_name\n",
    "        if os.path.exists(img_path):\n",
    "            im = Image.open(img_path).convert('RGB') #转换为灰度图，选项:1,L,P,RGB,RGBA,CMYK,YCbCr,I,F\n",
    "            imResize = im.resize((299, 299))\n",
    "            imageData = np.array(imResize)\n",
    "            images.append(imageData)\n",
    "            #(filename,extension) = os.path.splitext(img_name)\n",
    "\n",
    "            #labels.append(train_data['landmark_id'][img_num])\n",
    "            temp=img_name.split(\"_\")\n",
    "            temp=temp[3].split(\".\")\n",
    "            temp=temp[0].split(\"[\")\n",
    "            temp=temp[1].split(\"]\")\n",
    "            temp=temp[0].split(\",\")\n",
    "\n",
    "            each_label_list = [0] * 228\n",
    "            for j in range(0,len(temp)):\n",
    "                each_label_list[int(temp[j])-1]=1\n",
    "\n",
    "            labels.append(each_label_list)\n",
    "\n",
    "    X = np.array(images)\n",
    "    y=np.array(labels,dtype=np.float)\n",
    "    print(X.shape)\n",
    "\n",
    "    if(X.shape[0]>1):\n",
    "        X = X.reshape(X.shape[0],299,299,3).astype('float32')\n",
    "\n",
    "        #model.fit(X,[y,y],epochs=1,batch_size=BATCH_SIZE,verbose=1)\n",
    "        model.fit(X,y,validation_data=(X_val,y_val),epochs=1,batch_size=BATCH_SIZE,verbose=1)\n",
    "        \n",
    "    \n",
    "        \n",
    "# images_array = np.array(images)\n",
    "# labels_array = np.array(labels)\n",
    "# X = np.array(images)\n",
    "# y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('temp_RIV2_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
